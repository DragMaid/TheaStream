{% load static %}

<!DOCTYPE html>
<html>

<head>
    <title>Cambodian Theater</title>
    <link rel="stylesheet" href="{% static 'style.css' %}">
</head>

<body>

    <h1>Cambodian Theater Performance</h1>

    <!-- Video Player -->
    <video id="theater-video" width="720" height="400" controls autoplay muted>
        <source src="{{ video_url }}" type="video/mp4">
    </video>

    <!-- AI Chat Box -->
    <div id="ai-chat-box" style="margin-top: 20px;">
        <h2>Ask About the Performance</h2>
        <textarea id="user_message" placeholder="Type your question here..." rows="4" required
            style="width: 70%; padding: 10px; border-radius: 4px; border: 1px solid #555; font-size: 16px;"></textarea>
        <br>
        <button onclick="sendToAI()"
            style="padding: 10px 20px; margin-top: 10px; border-radius: 4px; background-color: #ffcc00; border: none; cursor: pointer;">
            Send
        </button>
    </div>

    <!-- Response Display -->
    <div id="ai-response-box" style="margin-top: 20px;">
        <h3>AI Response</h3>
        <p id="ai-response-text" style="font-style: italic;">Waiting for your question...</p>
    </div>

    <script>
        async function sendToAI() {
            const question = document.getElementById('user_message').value;
            const video = document.getElementById('theater-video');

            // Capture screenshot from video
            const canvas = document.createElement('canvas');
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            const ctx = canvas.getContext('2d');
            ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

            const blob = await new Promise(resolve => canvas.toBlob(resolve, 'image/jpeg'));

            // Create form data
            const formData = new FormData();
            formData.append('question', question);
            formData.append('screenshot', blob, 'screenshot.jpg');

            // Display loading
            document.getElementById('ai-response-text').innerText = "Thinking...";

            try {
                const response = await fetch('/ask-ai/', {
                    method: 'POST',
                    body: formData
                });

                const data = await response.json();
                document.getElementById('ai-response-text').innerText = data.response;
            } catch (error) {
                console.error(error);
                document.getElementById('ai-response-text').innerText = "Something went wrong.";
            }
        }
    </script>

    <script type="application/javascript" src="https://cdn.jsdelivr.net/npm/vosk-browser@0.0.5/dist/vosk.js"></script>
    <script>
        let mediaRecorder;
        let audioChunks = [];

        async function startRecording() {
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            mediaRecorder = new MediaRecorder(stream);

            audioChunks = [];

            mediaRecorder.ondataavailable = event => {
                audioChunks.push(event.data);
            };

            mediaRecorder.onstop = () => {
                const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                sendToServer(audioBlob);
            };

            mediaRecorder.start();

            setTimeout(() => {
                stopRecording();
            }, 8000); // or wait for silence
        }

        function stopRecording() {
            if (mediaRecorder && mediaRecorder.state === 'recording') {
                mediaRecorder.stop();
            }
        }

        async function sendToServer(audioBlob) {
            const formData = new FormData();
            formData.append("audio", audioBlob, "command.webm");

            const response = await fetch("/api/transcribe", {
                method: "POST",
                body: formData,
            });

            const result = await response.json();
            console.log("Whisper transcript:", result.text);
        }

        async function init() {
            // Load the Vosk model (make sure it's extracted, not a .zip file)
            const model = await Vosk.createModel('/static/models/model.zip');

            // Create a recognizer for 16kHz mono audio
            const recognizer = new model.KaldiRecognizer(16000);

            var snd = new Audio('/static/audio/listening.mp3');

            const call_lines = ["hey alex", "hi alex", "hello alex"];

            recognizer.on("result", (message) => {
                const transcript = message.result.text.trim().toLowerCase();
                {% comment %}console.log(`Result: ${transcript}`);{% endcomment %}
                if (call_lines.some(v => transcript.includes(v))) {
                    snd.play()
                    snd.currentTime = 0;
                    startRecording();
                }
            });

            const mediaStream = await navigator.mediaDevices.getUserMedia({
                audio: {
                    echoCancellation: true,
                    noiseSuppression: true,
                    channelCount: 1,
                },
                video: false,
            });

            const audioContext = new AudioContext({ sampleRate: 16000 });
            const recognizerNode = audioContext.createScriptProcessor(4096, 1, 1);

            recognizerNode.onaudioprocess = (event) => {
                try {
                    recognizer.acceptWaveform(event.inputBuffer);
                } catch (error) {
                    console.error('acceptWaveform failed', error);
                }
            };

            const source = audioContext.createMediaStreamSource(mediaStream);
            source.connect(recognizerNode);
            recognizerNode.connect(audioContext.destination); // Needed to keep the processor alive
        }

        window.onload = init;

    </script>

</body>

</html>
